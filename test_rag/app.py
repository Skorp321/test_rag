import streamlit as st
import os
from openai import OpenAI
from langchain_community.chat_models import ChatOpenAI
from langchain_community.retrievers import BM25Retriever
from langchain.retrievers import EnsembleRetriever
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_core.prompts import PromptTemplate
from langchain_core.documents import Document
from langchain.chains import RetrievalQA
from dotenv import load_dotenv
from bs4 import BeautifulSoup


load_dotenv()

class DocumentAgent:
    def __init__(self, openai_api_key):
        self.openai_api_key = openai_api_key
        self.llm = ChatOpenAI(
            openai_api_key=openai_api_key,
            openai_api_base="https://10f9698e-46b7-4a33-be37-f6495989f01f.modelrun.inference.cloud.ru/v1",
            model="qwen3:32b",
            temperature=0.1
        )
        self.embeddings = HuggingFaceEmbeddings(
            model_name="intfloat/multilingual-e5-large"
        )
        self.vectorstore = None
        self.qa_chain = None
        
    def load_html_document(self, html_content):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç HTML –¥–æ–∫—É–º–µ–Ω—Ç"""
        try:
            soup = BeautifulSoup(html_content, 'html.parser')

            for script in soup(["script", "style"]):
                script.decompose()

            text = soup.get_text()
            lines = (line.strip() for line in text.splitlines())
            chunks = (phrase.strip() for line in lines for phrase in line.split("  "))
            text = '\n'.join(chunk for chunk in chunks if chunk)

            doc = Document(page_content=text, metadata={"source": "uploaded_html"})
            text_splitter = RecursiveCharacterTextSplitter(
                chunk_size=500,
                chunk_overlap=150,
                separators=["\n\n", "\n", ". ", " ", ""]
            )
            
            documents = text_splitter.split_documents([doc])
            bm25 = BM25Retriever.from_documents(documents)
            bm25.k = 4
            faiss = FAISS.from_documents(documents, self.embeddings)
            retriever = faiss.as_retriever(
                search_type="similarity",
                k=4,
                score_threshold=None,
            )

            self.vectorstore = EnsembleRetriever(
                retrievers=[bm25, retriever],
                weights=[
                    0.5,
                    0.5,
                ],
            )
            
            self._create_qa_chain()
            
            return True, f"–î–æ–∫—É–º–µ–Ω—Ç —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω –∏ –æ–±—Ä–∞–±–æ—Ç–∞–Ω. –°–æ–∑–¥–∞–Ω–æ {len(documents)} —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤."
            
        except Exception as e:
            return False, f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞: {str(e)}"
    
    def _create_qa_chain(self):
        """–°–æ–∑–¥–∞–µ—Ç —Ü–µ–ø–æ—á–∫—É –≤–æ–ø—Ä–æ—Å-–æ—Ç–≤–µ—Ç"""
        template = """–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Å–ª–µ–¥—É—é—â–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –≤–æ–ø—Ä–æ—Å. 
        –ï—Å–ª–∏ –≤—ã –Ω–µ –∑–Ω–∞–µ—Ç–µ –æ—Ç–≤–µ—Ç–∞, —Å–∫–∞–∂–∏—Ç–µ, —á—Ç–æ –Ω–µ –∑–Ω–∞–µ—Ç–µ, –Ω–µ –ø—ã—Ç–∞–π—Ç–µ—Å—å –ø—Ä–∏–¥—É–º–∞—Ç—å –æ—Ç–≤–µ—Ç.
        –û—Ç–≤–µ—á–∞–π—Ç–µ –Ω–∞ —Ç–æ–º –∂–µ —è–∑—ã–∫–µ, –Ω–∞ –∫–æ—Ç–æ—Ä–æ–º –∑–∞–¥–∞–Ω –≤–æ–ø—Ä–æ—Å.

        –ö–æ–Ω—Ç–µ–∫—Å—Ç: {context}

        –í–æ–ø—Ä–æ—Å: {question}

        –û—Ç–≤–µ—Ç:"""
        
        prompt = PromptTemplate(
            template=template,
            input_variables=["context", "question"]
        )
        
        self.qa_chain = RetrievalQA.from_chain_type(
            llm=self.llm,
            chain_type="stuff",
            retriever=self.vectorstore,
            chain_type_kwargs={"prompt": prompt},
            return_source_documents=True
        )
    
    def ask_question(self, question):
        """–ó–∞–¥–∞–µ—Ç –≤–æ–ø—Ä–æ—Å –∞–≥–µ–Ω—Ç—É"""
        if not self.qa_chain:
            return "–û—à–∏–±–∫–∞: –î–æ–∫—É–º–µ–Ω—Ç –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –∑–∞–≥—Ä—É–∑–∏—Ç–µ HTML –¥–æ–∫—É–º–µ–Ω—Ç."
        
        try:
            result = self.qa_chain({"query": question})
            answer = result["result"]
            sources = result["source_documents"]
            return answer, sources
        except Exception as e:
            return f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–æ–ø—Ä–æ—Å–∞: {str(e)}", []

def main():
    load_dotenv()
    openai_api_key = os.getenv("OPENAI_API_KEY")

    if 'agent' not in st.session_state:
        try:
            st.session_state.agent = DocumentAgent(openai_api_key)
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –∞–≥–µ–Ω—Ç–∞: {str(e)}")
            st.stop()
    
    if 'chat_history' not in st.session_state:
        st.session_state.chat_history = []
    
    if 'document_loaded' not in st.session_state:
        st.session_state.document_loaded = False

    st.set_page_config(
        page_title="Document QA Agent",
        layout="wide"
    )

    st.markdown("<h2 style='text-align: center; color: white;'>Document QA Agent</h2>", unsafe_allow_html=True)
    st.markdown("<h6 style='text-align: center; color: white;'>–ê–≥–µ–Ω—Ç –¥–ª—è –æ—Ç–≤–µ—Ç–æ–≤ –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –ø–æ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—é HTML –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤</h6>", unsafe_allow_html=True)

    with st.sidebar:

        st.markdown("<h2 style='text-align: center; color: white;'>–ó–∞–≥—Ä—É–∑–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞</h2>", unsafe_allow_html=True)

        upload_option = st.radio(
            "–í—ã–±–µ—Ä–∏—Ç–µ —Å–ø–æ—Å–æ–± –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–∞:",
            ("–ó–∞–≥—Ä—É–∑–∏—Ç—å —Å–≤–æ–π —Ñ–∞–π–ª", "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ñ–∞–π–ª –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é")
        )
        
        default_file_path = "test_rag/doc.html"
        html_content = None
        
        if upload_option == "–ó–∞–≥—Ä—É–∑–∏—Ç—å —Å–≤–æ–π —Ñ–∞–π–ª":
            uploaded_file = st.file_uploader(
                "–í—ã–±–µ—Ä–∏—Ç–µ HTML —Ñ–∞–π–ª",
                type=['html'],
                help="–ó–∞–≥—Ä—É–∑–∏—Ç–µ HTML –¥–æ–∫—É–º–µ–Ω—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞"
            )
            if uploaded_file is not None:
                html_content = uploaded_file.read().decode('utf-8')
        else:
            if os.path.exists(default_file_path):
                with open(default_file_path, 'r', encoding='utf-8') as f:
                    html_content = f.read()
                st.success(f"–ó–∞–≥—Ä—É–∂–µ–Ω —Ñ–∞–π–ª –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: {default_file_path}")
            else:
                st.error(f"–§–∞–π–ª –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –Ω–µ –Ω–∞–π–¥–µ–Ω: {default_file_path}")
        
        if html_content and st.button("–û–±—Ä–∞–±–æ—Ç–∞—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç"):
            with st.spinner("–û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞..."):
                if hasattr(st.session_state, 'agent'):
                    success, message = st.session_state.agent.load_html_document(html_content)
                    if success:
                        st.success(message)
                        st.session_state.document_loaded = True
                    else:
                        st.error(message)
                        st.session_state.document_loaded = False
                else:
                    st.error("–ê–≥–µ–Ω—Ç –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∏—Ç–µ —Å—Ç—Ä–∞–Ω–∏—Ü—É.")

    st.markdown("<h2 style='text-align: center; color: white;'>–ß–∞—Ç —Å –∞–≥–µ–Ω—Ç–æ–º</h2>", unsafe_allow_html=True)

    if not hasattr(st.session_state, 'document_loaded') or not st.session_state.document_loaded:
        st.info("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –∑–∞–≥—Ä—É–∑–∏—Ç–µ –∏ –æ–±—Ä–∞–±–æ—Ç–∞–π—Ç–µ HTML –¥–æ–∫—É–º–µ–Ω—Ç –¥–ª—è –Ω–∞—á–∞–ª–∞ —Ä–∞–±–æ—Ç—ã.")
        return

    chat_container = st.container()
    
    with chat_container:
        for i, (question, answer) in enumerate(st.session_state.chat_history):
            with st.chat_message("user"):
                st.write(question)
            with st.chat_message("assistant"):
                st.write(answer)

        question = st.chat_input("–ó–∞–¥–∞–π—Ç–µ –≤–æ–ø—Ä–æ—Å –ø–æ –¥–æ–∫—É–º–µ–Ω—Ç—É...")
        
        if question:
            with st.chat_message("user"):
                st.write(question)

            with st.chat_message("assistant"):
                with st.spinner("–î—É–º–∞—é..."):
                    answer, sources = st.session_state.agent.ask_question(question)
                    st.write(answer)
                    st.session_state.chat_history.append((question, answer))

                    if sources and len(sources) > 0:
                        with st.expander("üìñ –ò—Å—Ç–æ—á–Ω–∏–∫–∏"):
                            for i, source in enumerate(sources):
                                st.text_area(
                                    f"–ò—Å—Ç–æ—á–Ω–∏–∫ {i+1}:",
                                    source.page_content,
                                    height=100
                                )

if __name__ == "__main__":
    main()